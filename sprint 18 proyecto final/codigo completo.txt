

print(" proyecto final")

import pandas as pd
from sklearn.model_selection import train_test_split
import lightgbm as lgb
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_auc_score, accuracy_score


#########################################################################################################################################################
df_contract= pd.read_csv('C:/Users/drgarciacabo/Music/tripleten/DS/sprint 18 proyecto final/final_provider/contract.csv')
df_internet= pd.read_csv('C:/Users/drgarciacabo/Music/tripleten/DS/sprint 18 proyecto final/final_provider/internet.csv')
df_personal= pd.read_csv('C:/Users/drgarciacabo/Music/tripleten/DS/sprint 18 proyecto final/final_provider/personal.csv')
df_phone= pd.read_csv('C:/Users/drgarciacabo/Music/tripleten/DS/sprint 18 proyecto final/final_provider/phone.csv')


#Analisis exploratorio
print("\n \n contract info:")
print(df_contract.head())
df_contract.info()

print("\n \n internet info:")
print(df_internet.head())
df_internet.info()

print("\n \n personal info:")
print(df_personal.head())
df_personal.info()

print("\n \n phone info:")
print(df_phone.head())
df_phone.info()




#Conversiones importantes 

# Convertir a numérico TotalCharges, usando coerce por si hay espacios en blanco
df_contract['TotalCharges'] = pd.to_numeric(df_contract['TotalCharges'], errors='coerce')
# Verificamos si hay valores nulos
print(df_contract['TotalCharges'].isna().sum())
#llenamos esos NaN con 0
df_contract['TotalCharges'] = df_contract['TotalCharges'].fillna(0)



#creamos una columna nueva de objetivo igual a EndDate pero ya en forma binaria
#si EndDate es NO, entonces tendrá un 0, caso contrario tendrá un 1
df_contract['target'] = (df_contract['EndDate'] != 'No').astype(int)



# Convertir BeginDate a datetime
df_contract['BeginDate'] = pd.to_datetime(df_contract['BeginDate'], format='mixed')

# Para hacer datetime el EndDate simplemente si su valor es 'No', usamos la fecha de corte febrero 2 del 2020
# caso contrario, usamos la fecha de fin.
df_contract['EndDate'] = df_contract['EndDate'].replace('No', '2020-02-01')
df_contract['EndDate'] = pd.to_datetime(df_contract['EndDate'], format='mixed')

# Con las columnas en su formato calculamos los días de permanencia 
df_contract['tenure'] = (df_contract['EndDate'] - df_contract['BeginDate']).dt.days

print("\n \n contract info updated:")
print(df_contract.head())
df_contract.info()



#EDA 
#Veremos la diferencia en numero de clientes que cancelan y que no
plt.figure(figsize=(8, 5))
sns.countplot(x='target', data=df_contract, palette='viridis')
plt.title('Distribución de la cancelación de los clientes')
plt.xlabel('0 No, 1 Sí')
plt.ylabel('Número de clientes')
plt.show()

print("porcentajes de cancelación ")
print(df_contract['target'].value_counts(normalize=True) * 100)


#Veremos la relación entre la cancelación y el tipo de contrato
plt.figure(figsize=(8, 5))
sns.countplot(x='Type', hue='target', data=df_contract)
plt.title('Cancelación por contrato')
plt.xlabel('Tipo de contrato')
plt.ylabel('Número de clientes')
plt.legend(title='Churn', labels=['Se queda', 'Se va'])
plt.show()


#Veremos la relación ente las cancelaciones y los cargos mensuales
plt.figure(figsize=(8, 5))
sns.boxplot(hue='target', y='MonthlyCharges', data=df_contract, palette='viridis', legend=False)
plt.title('Distribución de cargos mensuales por cancelación')
plt.xlabel('0  No, 1 Si)')
plt.ylabel('Cargos mensuales')
plt.show()





#########################################################################################################################################################

# Vamos a combinar todos los dataframes
# Utilizaremos la unión izquierda a través del customerID

df_full = df_contract.merge(df_personal, on='customerID', how='left')
df_full = df_full.merge(df_internet, on='customerID', how='left')
df_full = df_full.merge(df_phone, on='customerID', how='left')


# Dado que 'costumer_id' es un columna con información sobre identificadores unicos
#podemos considerarla irrelevante para el modelo, por lo que la quitaremos
#lo mismo para las fechas de inicio y final ya que con la columna de permanencia es suficiente
df_full = df_full.drop(['customerID'], axis=1)
df_full = df_full.drop(['BeginDate'], axis=1)
df_full = df_full.drop(['EndDate'], axis=1)


df_full.info()

# Después de la unión, las columnas de servicios quedaron con NaN
# Vamos a rellenar esos vacíos con 'No' usando fillna 

#crearemos una lista con las columnas de servicios 
services = [
    'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
    'TechSupport', 'StreamingTV', 'StreamingMovies', 'MultipleLines'
]

for col in services:
    df_full[col] = df_full[col].fillna('No')




train_df, val_df = train_test_split( df_full,test_size=0.25,random_state=12345)

features_train=train_df[train_df.columns.drop('target')]
target_train=train_df['target']

features_val=val_df[val_df.columns.drop('target')]
target_val=val_df['target']



lgbm_train = features_train.copy()
lgbm_val = features_val.copy()

#tomamos las columnas de tipo categoria
categorical_features = lgbm_train.select_dtypes(include=['object']).columns

#cada una de las columnas las volvemos tipo category
for col in categorical_features:
    lgbm_train[col] = lgbm_train[col].astype('category')
    lgbm_val[col] = lgbm_val[col].astype('category')

#creamos y entrenamos el modelo 
model_lgbm = lgb.LGBMClassifier( 
    n_estimators= 2000,  #numero de arboles
    max_depth= 13, #profundidad máxima
    random_state=12345,
    is_unbalance=True, #lo activamos para compensar desequilibrio de clases
    learning_rate=0.01, #taza de aprendizaje
    objective="binary", #lo marcamos como clasificación binaria
    feature_fraction=0.8, #fracción para prevenir sobreajuste
    num_leaves=64 #controlar complejidad del arbol
    
    )
model_lgbm.fit( lgbm_train, target_train,categorical_feature=list(categorical_features),eval_metric='auc',)

# Evaluación
probs = model_lgbm.predict_proba(lgbm_val)[:, 1]
# Predicciones (clases 0 o 1 usando un umbral de 0.5)
preds = (probs > 0.5).astype(int)

auc_score = roc_auc_score(target_val, probs)
acc_score = accuracy_score(target_val, preds)

print(f"AUC-ROC final: {auc_score:.4f}")
print(f"Exactitud: {acc_score:.4f}")



importances = pd.DataFrame({
    'feature': lgbm_train.columns,
    'importance': model_lgbm.feature_importances_
}).sort_values(by='importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances)
plt.title('Importancia de las Características (Feature Importance)')
plt.show()





